# classifier.py
# Klasyfikator zgÅ‚oszeÅ„ - kategoryzacja na podstawie reguÅ‚ JSON

import pandas as pd
import re
import string
import logging
import unicodedata
from rules_manager import rules_manager, RulesSecurityError, RulesValidationError

import warnings
warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning, module='pandas')
warnings.filterwarnings('ignore', message='.*DataFrame.dtypes.*')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Limity bezpieczeÅ„stwa
MAX_RULES_LIMIT = 1000
MAX_TITLE_LENGTH = 500
ALLOWED_CATEGORY_CHARS = string.ascii_letters + string.digits + "_- /," + "Ä…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼Ä„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»"

class ProblemClassifier:
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.label_encoder = None
        self.feature_names = None
        self.model_package = None
        self.rules_manager = rules_manager
        self.load_model()

    def _normalize_text(self, text):
        """
        Normalizacja tekstu - usuwanie polskich znakÃ³w diakrytycznych.
        PrzykÅ‚ad: "zuÅ¼ycie" â†’ "zuzycie", "poÅ‚Ä…czenie" â†’ "polaczenie"
        """
        if not isinstance(text, str):
            return text
        
        # Mapowanie polskich znakÃ³w diakrytycznych
        polish_chars = {
            'Ä…': 'a', 'Ä‡': 'c', 'Ä™': 'e', 'Å‚': 'l', 'Å„': 'n', 
            'Ã³': 'o', 'Å›': 's', 'Åº': 'z', 'Å¼': 'z',
            'Ä„': 'A', 'Ä†': 'C', 'Ä˜': 'E', 'Å': 'L', 'Åƒ': 'N',
            'Ã“': 'O', 'Åš': 'S', 'Å¹': 'Z', 'Å»': 'Z'
        }
        
        # ZastÄ…p polskie znaki
        normalized = text
        for polish, latin in polish_chars.items():
            normalized = normalized.replace(polish, latin)
        
        return normalized

    def load_model(self):
        """Inicjalizacja klasyfikatora - uÅ¼ywamy tylko reguÅ‚ JSON (bez ML)."""
        self.model = None
        logger.info("âœ… Klasyfikator skonfigurowany do uÅ¼ywania wyÅ‚Ä…cznie reguÅ‚ JSON.")

    def classify_issues(self, df):
        """Klasyfikuje zgÅ‚oszenia za pomocÄ… reguÅ‚."""
        # Walidacja wymaganych kolumn
        required_columns = ['title']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            error_msg = f"DataFrame nie zawiera wymaganych kolumn: {missing_columns}"
            logger.error(f"BÅÄ„D WALIDACJI: {error_msg}")
            raise ValueError(error_msg)
        
        logger.info("ðŸ”§ Rozpoczynanie klasyfikacji reguÅ‚owej...")
        return self._classify_with_rules(df)

    def _classify_with_rules(self, df):
        """GÅ‚Ã³wna logika klasyfikacji na podstawie reguÅ‚ JSON."""
        logger.info("RozpoczÄ™to klasyfikacjÄ™ reguÅ‚owÄ…. Liczba zgÅ‚oszeÅ„: %d", len(df))
        df_copy = df.copy()
        
        # Walidacja kolumny 'title'
        if 'title' not in df_copy.columns:
            logger.error("BÅÄ„D WALIDACJI: Brak kolumny 'title' w DataFrame")
            raise ValueError("DataFrame musi zawieraÄ‡ kolumnÄ™ 'title'")
        
        # Normalizacja tytuÅ‚Ã³w do lowercase
        try:
            df_copy['title_lower'] = df_copy['title'].astype(str).str.lower()
        except Exception as e:
            logger.error(f"BÅÄ„D konwersji kolumny 'title': {e}")
            df_copy['title_lower'] = ''
        
        # Ograniczenie dÅ‚ugoÅ›ci tekstu
        df_copy['title_lower'] = df_copy['title_lower'].str.slice(0, MAX_TITLE_LENGTH)
        
        # Wykluczenie zgÅ‚oszeÅ„ z frazÄ… "telefon do"
        telefon_do_mask = df_copy['title_lower'].str.contains('telefon do', case=False, na=False)
        excluded_count = telefon_do_mask.sum()
        
        if excluded_count > 0:
            logger.info(f"ðŸ”‡ Wykluczono {excluded_count} zgÅ‚oszeÅ„ zawierajÄ…cych 'telefon do' z klasyfikacji")
        
        df_copy['category'] = 'inne'
        df_copy['confidence'] = 0.5

        # Wczytanie reguÅ‚ z JSON
        try:
            self.rules_manager.reload_rules()
            rules_dict = self.rules_manager.get_rules()
            
            # Limit maksymalnej liczby reguÅ‚
            if len(rules_dict) > MAX_RULES_LIMIT:
                logger.warning(f"Przekroczono limit reguÅ‚ ({len(rules_dict)} > {MAX_RULES_LIMIT}). Ograniczam.")
                rules_dict = dict(list(rules_dict.items())[:MAX_RULES_LIMIT])
            
            logger.info(f"ðŸ”„ Wczytano {len(rules_dict)} reguÅ‚ z JSON")
        except (RulesSecurityError, RulesValidationError) as e:
            logger.error(f"âŒ BÅ‚Ä…d podczas Å‚adowania reguÅ‚: {e}")
            return df_copy
        except Exception as e:
            logger.exception(f"âŒ BÅ‚Ä…d podczas Å‚adowania reguÅ‚ klasyfikacji: {e}")
            return df_copy

        classified_count = 0
        for category, rule in rules_dict.items():
            # Walidacja nazwy kategorii
            if not self._validate_category_name(category):
                logger.warning(f"PominiÄ™to kategoriÄ™ z niedozwolonymi znakami: {category}")
                continue
                
            for idx, row in df_copy.iterrows():
                # PomiÅ„ zgÅ‚oszenia z frazÄ… "telefon do"
                if telefon_do_mask.iloc[idx]:
                    continue
                
                # Walidacja title_lower
                title_lower = row.get('title_lower', '')
                if pd.isna(title_lower) or not isinstance(title_lower, str):
                    title_lower = ''
                
                score = self._calculate_rule_score(title_lower, rule)
                if score >= rule.get('min_score', 1) and df_copy.loc[idx, 'category'] == 'inne':
                    df_copy.loc[idx, 'category'] = category
                    df_copy.loc[idx, 'confidence'] = min(0.9, 0.6 + score * 0.1)
                    classified_count += 1
        
        logger.info("Klasyfikacja reguÅ‚owa zakoÅ„czona. Sklasyfikowano: %d zgÅ‚oszeÅ„", classified_count)
        if excluded_count > 0:
            logger.info(f"ðŸ“Š Podsumowanie: {classified_count} sklasyfikowanych, {excluded_count} wykluczonych ('telefon do'), {len(df_copy) - classified_count - excluded_count} pozostaÅ‚o w kategorii 'inne'")
        else:
            logger.info(f"ðŸ“Š Podsumowanie: {classified_count} sklasyfikowanych, {len(df_copy) - classified_count} pozostaÅ‚o w kategorii 'inne'")
        return df_copy

    def _validate_category_name(self, category_name):
        """Waliduje nazwÄ™ kategorii - dozwolone: litery, cyfry, podkreÅ›lenie, myÅ›lnik."""
        if not category_name or not isinstance(category_name, str):
            return False
        
        for char in category_name:
            if char not in ALLOWED_CATEGORY_CHARS:
                return False
        
        if len(category_name) > 100:
            return False
            
        return True

    def _calculate_rule_score(self, title_lower, rule):
        """
        Oblicza wynik dopasowania tytuÅ‚u do reguÅ‚y.
        
        Mechanizm dopasowywania:
        - Keywords: dopasowanie czÄ™Å›ciowe ("zawiesz" â†’ "zawieszony")
        - Combinations: wszystkie sÅ‚owa muszÄ… wystÄ…piÄ‡ jako podciÄ…gi
        - Forbidden: jeÅ›li znajdzie - odrzuca reguÅ‚Ä™
        - Normalizacja polskich znakÃ³w ("zuÅ¼ycie" â†’ "zuzycie")
        
        Punktacja: keyword=1pkt, kombinacja 2sÅ‚Ã³w=3pkt, 3sÅ‚Ã³w=4pkt
        """
        # Walidacja danych wejÅ›ciowych
        if not isinstance(title_lower, str):
            logger.warning(f"title_lower nie jest stringiem: {type(title_lower)}")
            return 0
        
        if not isinstance(rule, dict):
            logger.warning(f"reguÅ‚a nie jest sÅ‚ownikiem: {type(rule)}")
            return 0
        
        # Ograniczenie dÅ‚ugoÅ›ci tekstu
        if len(title_lower) > MAX_TITLE_LENGTH:
            title_lower = title_lower[:MAX_TITLE_LENGTH]
            logger.warning(f"ObciÄ™to tytuÅ‚ do {MAX_TITLE_LENGTH} znakÃ³w")
        
        # Normalizacja tekstu (polskie znaki)
        title_normalized = self._normalize_text(title_lower)
        logger.debug(f"ðŸ”¤ Znormalizowano: '{title_lower}' â†’ '{title_normalized}'")
        
        score = 0
        
        # Sprawdzenie zabronionych sÅ‚Ã³w
        try:
            if 'forbidden' in rule and isinstance(rule['forbidden'], list):
                for forbidden in rule['forbidden']:
                    if isinstance(forbidden, str):
                        forbidden_normalized = self._normalize_text(forbidden)
                        if (forbidden in title_lower or 
                            forbidden_normalized in title_normalized or
                            forbidden in title_normalized):
                            logger.debug(f"ðŸš« Forbidden '{forbidden}' - odrzucam reguÅ‚Ä™")
                            return 0
        except Exception as e:
            logger.error(f"BÅ‚Ä…d sprawdzania forbidden: {e}")
        
        # Sprawdzenie wymaganych kombinacji
        try:
            if 'required_combinations' in rule and isinstance(rule['required_combinations'], list):
                for combination in rule['required_combinations']:
                    if isinstance(combination, list):
                        # Dopasowanie czÄ™Å›ciowe z normalizacjÄ…
                        all_words_found = True
                        for word in combination:
                            if not isinstance(word, str):
                                all_words_found = False
                                break
                            
                            word_normalized = self._normalize_text(word)
                            word_found = (word in title_lower or 
                                        word_normalized in title_normalized or
                                        word in title_normalized)
                            
                            if not word_found:
                                all_words_found = False
                                break
                        
                        if all_words_found:
                            if len(combination) == 2:
                                score += 3
                                logger.debug(f"ðŸŽ¯ Kombinacja 2-sÅ‚owna: {combination}")
                            elif len(combination) == 3:
                                score += 4
                                logger.debug(f"ðŸŽ¯ Kombinacja 3-sÅ‚owna: {combination}")
                            else:
                                score += len(combination)
                                logger.debug(f"ðŸŽ¯ Kombinacja {len(combination)}-sÅ‚owna: {combination}")
        except Exception as e:
            logger.error(f"BÅ‚Ä…d sprawdzania kombinacji: {e}")

        # Sprawdzenie keywords
        try:
            if 'keywords' in rule and isinstance(rule['keywords'], list):
                for keyword in rule['keywords']:
                    if isinstance(keyword, str):
                        try:
                            # Dopasowanie czÄ™Å›ciowe z normalizacjÄ…
                            escaped_keyword = re.escape(keyword)
                            keyword_normalized = self._normalize_text(keyword)
                            escaped_keyword_normalized = re.escape(keyword_normalized)
                            
                            original_match = re.search(escaped_keyword, title_lower)
                            normalized_match = re.search(escaped_keyword_normalized, title_normalized)
                            cross_match = re.search(escaped_keyword, title_normalized)
                            
                            if original_match or normalized_match or cross_match:
                                score += 1
                                logger.debug(f"ðŸŽ¯ Keyword '{keyword}'")
                        except re.error as regex_err:
                            logger.warning(f"BÅ‚Ä…d regex dla '{keyword}': {regex_err}")
        except Exception as e:
            logger.error(f"BÅ‚Ä…d sprawdzania keywords: {e}")
        
        return score
